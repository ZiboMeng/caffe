I0622 11:31:56.443043 17283 caffe.cpp:185] Using GPUs 2
I0622 11:31:56.461858 17283 caffe.cpp:190] GPU 2: GeForce GTX 980
I0622 11:31:56.823426 17283 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1
test_interval: 50
base_lr: 5e-05
display: 100
max_iter: 500000
lr_policy: "step"
gamma: 0.5
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 500000
snapshot_prefix: "examples/FER2013/models/fer13_finetune_21000_siamese/fer2013"
solver_mode: GPU
device_id: 2
net: "examples/FER2013/scripts/fer13_siamese_fersfew/fer13_siamese.prototxt"
I0622 11:31:56.823729 17283 solver.cpp:91] Creating training net from net file: examples/FER2013/scripts/fer13_siamese_fersfew/fer13_siamese.prototxt
I0622 11:31:56.826009 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_p
I0622 11:31:56.826030 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer silence
I0622 11:31:56.826037 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer silence
I0622 11:31:56.826045 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0622 11:31:56.826082 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer conv11_p
I0622 11:31:56.826117 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer score
I0622 11:31:56.826125 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer score
I0622 11:31:56.826133 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_testing
I0622 11:31:56.826140 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_training
I0622 11:31:56.826151 17283 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_exp_p
I0622 11:31:56.826875 17283 net.cpp:49] Initializing net from parameters: 
name: "SiameseNet"
state {
  phase: TRAIN
}
layer {
  name: "pair_data"
  type: "ImageData"
  top: "pair_data"
  top: "labels"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 48
  }
  image_data_param {
    source: "examples/SFEW/data/siamese_bi_multi_withfer/Train/train"
    batch_size: 64
    shuffle: true
    new_height: 60
    new_width: 60
    is_color: false
    root_folder: "/home/zibo/Data/Database/SFEW_60x60/"
    image_num: 2
    label_dim: 4
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "slice_tri"
  type: "Slice"
  bottom: "labels"
  top: "sim"
  top: "label1"
  top: "label2"
  top: "subsim"
  include {
    phase: TRAIN
  }
  slice_param {
    slice_dim: 1
    slice_point: 1
    slice_point: 2
    slice_point: 3
  }
}
layer {
  name: "conv11"
  type: "Convolution"
  bottom: "data"
  top: "conv11"
  param {
    name: "conv11_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv11_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu11"
  type: "PReLU"
  bottom: "conv11"
  top: "conv11"
}
layer {
  name: "bn11"
  type: "BatchNorm"
  bottom: "conv11"
  top: "bn11"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "bn11"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv21"
  type: "Convolution"
  bottom: "pool1"
  top: "conv21"
  param {
    name: "conv21_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv21_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu21"
  type: "PReLU"
  bottom: "conv21"
  top: "conv21"
}
layer {
  name: "bn21"
  type: "BatchNorm"
  bottom: "conv21"
  top: "bn21"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "bn21"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv31"
  type: "Convolution"
  bottom: "pool2"
  top: "conv31"
  param {
    name: "conv31_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv31_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu31"
  type: "PReLU"
  bottom: "conv31"
  top: "conv31"
}
layer {
  name: "bn31"
  type: "BatchNorm"
  bottom: "conv31"
  top: "bn31"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "fc4"
  type: "InnerProduct"
  bottom: "bn31"
  top: "fc4"
  param {
    name: "fc4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc4_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "PReLU"
  bottom: "fc4"
  top: "fc4"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "fc4"
  top: "fc4"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.6
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5"
  param {
    name: "fc5_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc5_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "PReLU"
  bottom: "fc5"
  top: "fc5"
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "fc5"
  top: "fc5"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.6
  }
}
layer {
  name: "fc5_sub"
  type: "InnerProduct"
  bottom: "fc4"
  top: "fc5_sub"
  param {
    name: "fc5_sub_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc5_sub_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5_sub"
  type: "PReLU"
  bottom: "fc5_sub"
  top: "fc5_sub"
}
layer {
  name: "drop5_sub"
  type: "Dropout"
  bottom: "fc5_sub"
  top: "fc5_sub"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.6
  }
}
layer {
  name: "concat"
  type: "Concat"
  bottom: "fc5"
  bottom: "fc5_sub"
  top: "features"
}
layer {
  name: "pred_new"
  type: "InnerProduct"
  bottom: "features"
  top: "pred_new"
  param {
    name: "pred_w"
    lr_mult: 10
    decay_mult: 1
  }
  param {
    name: "pred_b"
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv11_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv11_p"
  param {
    name: "conv11_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv11_b"
    lr_mult: 2
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu11_p"
  type: "PReLU"
  bottom: "conv11_p"
  top: "conv11_p"
}
layer {
  name: "bn11_p"
  type: "BatchNorm"
  bottom: "conv11_p"
  top: "bn11_p"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "bn11_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv21_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv21_p"
  param {
    name: "conv21_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv21_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu21_p"
  type: "PReLU"
  bottom: "conv21_p"
  top: "conv21_p"
}
layer {
  name: "bn21_p"
  type: "BatchNorm"
  bottom: "conv21_p"
  top: "bn21_p"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "bn21_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
  }
}
layer {
  name: "conv31_p"
  type: "Convolution"
  bottom: "pool2_p"
  top: "conv31_p"
  param {
    name: "conv31_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "conv31_b"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu31_p"
  type: "PReLU"
  bottom: "conv31_p"
  top: "conv31_p"
}
layer {
  name: "bn31_p"
  type: "BatchNorm"
  bottom: "conv31_p"
  top: "bn31_p"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name: "fc4_p"
  type: "InnerProduct"
  bottom: "bn31_p"
  top: "fc4_p"
  param {
    name: "fc4_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc4_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4_p"
  type: "PReLU"
  bottom: "fc4_p"
  top: "fc4_p"
}
layer {
  name: "drop4_p"
  type: "Dropout"
  bottom: "fc4_p"
  top: "fc4_p"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.6
  }
}
layer {
  name: "fc5_p"
  type: "InnerProduct"
  bottom: "fc4_p"
  top: "fc5_p"
  param {
    name: "fc5_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc5_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5_p"
  type: "PReLU"
  bottom: "fc5_p"
  top: "fc5_p"
}
layer {
  name: "drop5_p"
  type: "Dropout"
  bottom: "fc5_p"
  top: "fc5_p"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.6
  }
}
layer {
  name: "fc5_p_sub"
  type: "InnerProduct"
  bottom: "fc4_p"
  top: "fc5_p_sub"
  param {
    name: "fc5_sub_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "fc5_sub_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "gaussian"
      std: 0.0001
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5_p_sub"
  type: "PReLU"
  bottom: "fc5_p_sub"
  top: "fc5_p_sub"
}
layer {
  name: "drop5_p_sub"
  type: "Dropout"
  bottom: "fc5_p_sub"
  top: "fc5_p_sub"
  include {
    phase: TRAIN
  }
  dropout_param {
    dropout_ratio: 0.6
  }
}
layer {
  name: "concat_p"
  type: "Concat"
  bottom: "fc5_p"
  bottom: "fc5_p_sub"
  top: "features_p"
}
layer {
  name: "pred_new_p"
  type: "InnerProduct"
  bottom: "features_p"
  top: "pred_new_p"
  param {
    name: "pred_w"
    lr_mult: 10
    decay_mult: 1
  }
  param {
    name: "pred_b"
    lr_mult: 20
    decay_mult: 0
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pred"
  type: "InnerProduct"
  bottom: "fc5"
  top: "pred"
  param {
    name: "pred_exp_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "pred_exp_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "pred_p"
  type: "InnerProduct"
  bottom: "fc5_p"
  top: "pred_p"
  param {
    name: "pred_exp_w"
    lr_mult: 1
    decay_mult: 1
  }
  param {
    name: "pred_exp_b"
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_contrastive"
  type: "ContrastiveLoss"
  bottom: "fc5"
  bottom: "fc5_p"
  bottom: "sim"
  top: "contrastive_loss_label"
  loss_weight: 1
  include {
    phase: TRAIN
  }
  contrastive_loss_param {
    margin: 10
  }
}
layer {
  name: "loss_contrastive_sub"
  type: "ContrastiveLoss"
  bottom: "fc5_sub"
  bottom: "fc5_p_sub"
  bottom: "subsim"
  top: "contrastive_loss_sub"
  loss_weight: 5
  include {
    phase: TRAIN
  }
  contrastive_loss_param {
    margin: 10
  }
}
layer {
  name: "loss_1"
  type: "SoftmaxWithLoss"
  bottom: "pred_new"
  bottom: "label1"
  top: "loss_1"
}
layer {
  name: "accuracy1"
  type: "Accuracy"
  bottom: "pred_new"
  bottom: "label1"
  top: "accuracy1"
  include {
    phase: TRAIN
  }
}
layer {
  name: "accuracy2"
  type: "Accuracy"
  bottom: "pred_new_p"
  bottom: "label2"
  top: "accuracy2"
  include {
    phase: TRAIN
  }
}
layer {
  name: "accuracy_exp"
  type: "Accuracy"
  bottom: "pred"
  bottom: "label1"
  top: "accuracy_exp"
}
layer {
  name: "accuracy_exp_p"
  type: "Accuracy"
  bottom: "pred_p"
  bottom: "label2"
  top: "accuracy_exp_p"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss_2"
  type: "SoftmaxWithLoss"
  bottom: "pred_new_p"
  bottom: "label2"
  top: "loss_2"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss_exp"
  type: "SoftmaxWithLoss"
  bottom: "pred"
  bottom: "label1"
  top: "loss_exp"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss_exp_p"
  type: "SoftmaxWithLoss"
  bottom: "pred_p"
  bottom: "label2"
  top: "loss_exp_p"
  loss_weight: 1
  include {
    phase: TRAIN
  }
}
I0622 11:31:56.827431 17283 layer_factory.hpp:77] Creating layer pair_data
I0622 11:31:56.827496 17283 net.cpp:91] Creating Layer pair_data
I0622 11:31:56.827517 17283 net.cpp:399] pair_data -> pair_data
I0622 11:31:56.827596 17283 net.cpp:399] pair_data -> labels
I0622 11:31:56.828169 17283 image_data_layer.cpp:40] Opening file examples/SFEW/data/siamese_bi_multi_withfer/Train/train
*** Aborted at 1466611000 (unix time) try "date -d @1466611000" if you are using GNU date ***
PC: @     0x7f61138cf10d std::__uninitialized_copy<>::__uninit_copy<>()
*** SIGTERM (@0x3e800001e62) received by PID 17283 (TID 0x7f611434da00) from PID 7778; stack trace: ***
    @     0x7f6112753cb0 (unknown)
    @     0x7f61138cf10d std::__uninitialized_copy<>::__uninit_copy<>()
    @     0x7f61138cf3dd std::vector<>::_M_insert_aux()
    @     0x7f61138d16d4 caffe::ImageDataLayer<>::DataLayerSetUp()
    @     0x7f61139b5343 caffe::BasePrefetchingDataLayer<>::LayerSetUp()
    @     0x7f61138a3056 caffe::Net<>::Init()
    @     0x7f61138a3ef5 caffe::Net<>::Net()
    @     0x7f61139c22ba caffe::Solver<>::InitTrainNet()
    @     0x7f61139c33bc caffe::Solver<>::Init()
    @     0x7f61139c36ea caffe::Solver<>::Solver()
    @     0x7f6113888ee3 caffe::Creator_SGDSolver<>()
    @           0x40e95e caffe::SolverRegistry<>::CreateSolver()
    @           0x407b22 train()
    @           0x4059ac main
    @     0x7f611273ef45 __libc_start_main
    @           0x4060e1 (unknown)
    @                0x0 (unknown)
